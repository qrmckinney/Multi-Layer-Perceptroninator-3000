{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ee04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AskUserWhatToDo():\n",
    "    choice=0\n",
    "    loss_history=[]\n",
    "    accuracy_history=[]\n",
    "    while (choice == 0):\n",
    "        print(\"\\n\\nSelect an option by typing the Indicated letter and pressing  \\\"Enter\\\" \\n\\n\")\n",
    "        print(\"a:  Load csv of data to model\")\n",
    "        print(\"b: Partition  loaded data into Training, Testing, and Validation\")\n",
    "        print(\"c: Manually Define MLP Architecture which is compatible with loaded data\")\n",
    "        print(\"d: Load MLP Architecture From Previous Session which is compatible with loaded data\")\n",
    "        print(\"e: Initialize weights and biases for use with training\")\n",
    "        print(\"f: Load weights and biases from previous session\")\n",
    "        print(\"g: Save Current Architecture For Future Session\")\n",
    "        print(\"h: Save Current Weights For Future Session\")\n",
    "        print(\"i: Choose Training Parameters\")\n",
    "        print(\"j: Save Training Parameters\")\n",
    "        print(\"k: Load Training Parameters\")\n",
    "        print(\"l: Quit Program Without Saving\")\n",
    "        print(\"m: Train Model\")\n",
    "        print(\"n: Test Models\")\n",
    "        print(\"o: Print Accuracy History\")\n",
    "        print(\"p: Print Loss History\")\n",
    "    \n",
    "        x=input(\"Your Choice: \")\n",
    "    \n",
    "        if (x=='a'):\n",
    "            current_loaded_data=load_data()\n",
    "            current_data_size=current_loaded_data.shape[1]-1\n",
    "        elif (x=='b'):\n",
    "            current_loaded_data=partition_current_loaded_data(current_loaded_data)\n",
    "            current_data_size=current_loaded_data.shape[1]-1\n",
    "        elif (x=='c'):\n",
    "            current_working_architecture=define_architecture(current_data_size)\n",
    "        elif (x=='d'):\n",
    "            current_working_architecture=load_architecture()\n",
    "        elif (x=='e'):\n",
    "            current_working_weights=initialize_weights(current_working_architecture)\n",
    "        elif (x=='f'):\n",
    "            current_working_weights=load_weights()\n",
    "        elif(x=='g'):\n",
    "            save_architecture(current_working_architecture)\n",
    "        elif(x=='h'):\n",
    "            save_weights(current_working_weights)\n",
    "        elif (x=='i'):\n",
    "            learning_parameters=set_training_parameters()\n",
    "        elif(x=='j'):\n",
    "            save_training_parameters(learning_parameters)\n",
    "        elif (x=='k'):\n",
    "            learning_parameters=load_training_parameters()\n",
    "        elif (x=='l'):\n",
    "            choice = 1\n",
    "        elif (x=='m'):\n",
    "            current_working_weights, loss_history, accuracy_history= train_model(current_loaded_data, current_working_architecture, current_working_weights, learning_parameters, loss_history, accuracy_history)\n",
    "        elif (x=='n'):\n",
    "            loss_history, accuracy_history= test_data(current_loaded_data, current_working_architecture, current_working_weights, learning_parameters)\n",
    "        elif (x=='o'):\n",
    "            print_out(accuracy_history, \"accuracy\")\n",
    "        elif (x=='p'):\n",
    "            print_out(loss_history, \"Loss\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7fba634-3665-4e5a-8697-93db39ad57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(history, name):\n",
    "    x=[]\n",
    "    array_hy=np.shape(np.array(history))\n",
    "    hy_size=np.squeeze(array_hy)\n",
    "    print(hy_size)\n",
    "    for y in range(0,hy_size):\n",
    "        x.append(y*100)\n",
    "    plt.plot(x, history)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(name)\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357d1260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function loads data to be modeled from a file and vectorizes it, distinguishing between the input and the output\n",
    "def load_data():\n",
    "    print(\"\\nPlease provide the file name of the csv that you would like to read as data.\\n\")\n",
    "    print(\"Each line of this File should represent a single data point, and the first entry of each line should indicate to what class a given data point belongs\\n\")\n",
    "    print(\"Your selection should include the .csv as its extension\\n\")\n",
    "    filename=input(\"Filename: \")\n",
    "    return load_particular_data(filename)\n",
    "\n",
    "          \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7cb84f-e1d1-45c3-a87f-875358fab95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function allows the user to choose their loss function, learning rate, and l2 regularizer hyperparameters\n",
    "def set_training_parameters():\n",
    "    chosen_learning_rate=float(input(\"What learning rate would you like to use?\"))\n",
    "    chosen_l2_regularizer=float(input(\"What hyperparameter would you like to use for the\\n L2 regularizer? (If no regularizer is to be used, hit '0'\"))\n",
    "    print(\"The options for loss functions are as follows:\")\n",
    "    print(\"a.) cross entropy with softmax\")\n",
    "    print(\"b.) hinge loss\")\n",
    "    loss_choice=input(\"Your choice: \")\n",
    "    if (loss_choice=='a'):\n",
    "        loss_function=\"cross_entropy\"\n",
    "    elif (loss_choice=='b'):\n",
    "        loss_function=\"hinge_loss\"\n",
    "        \n",
    "    training_parameters={\"l2_regularizer\": chosen_l2_regularizer,\n",
    "        \"learning_rate\": chosen_learning_rate, \n",
    "        \"loss_function\":loss_function\n",
    "    }\n",
    "    return training_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021d867b-0b2c-48f4-9bb7-9d02c41cb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function saves the currently loaded learning parameters to a file\n",
    "def save_training_parameters(parameters):\n",
    "    file_name=input(\"What filename would you like to save the training parameters to?\")\n",
    "    parameter_list=[parameters]\n",
    "    open_file=open(file_name,\"wb\")\n",
    "    pickle.dump(parameter_list,open_file)\n",
    "    open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88766a8-dd51-4504-b75c-e8c58a891476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function loads the currently loaded learning parameters to a file\n",
    "def load_training_parameters():\n",
    "    filename=input(\"Please give the filename of the training parameters you would like to load\")\n",
    "    open_file=open(filename, \"rb\")\n",
    "    loaded_list=pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    for x in loaded_list:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696fa42b-829b-4091-aab0-d236720d8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function loads data from a predetermined filename\n",
    "def load_particular_data(filename):\n",
    "    raw_data=open(filename, 'rt')\n",
    "    reader=csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    x=list(reader)\n",
    "    convertedx=np.array(x)\n",
    "    data=convertedx.astype(np.float64)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcec6f12-4fa1-4703-afc0-827dafe4f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION PARTRITIONS THE CURRENTLY LOADED DATA AND SAVES IT TO MULTIPLE FILES THEN GIVES THE USER THE OPTION TO START WORKING WITH THE DIFFERENT DATA\n",
    "def partition_current_loaded_data(data):\n",
    "    print(\"\\nThis module partitions the current loaded data into training, testing, and validation datasets\")\n",
    "    print(\"and then saves each of those datasets to csv files for future use. At the end of the use of this\")\n",
    "    print(\"module, you will be asked whether or not you want to change your currently loaded data to the new\")\n",
    "    print(\"one of the newly created data files, or if you want to stick with the loaded data you had at the \")\n",
    "    print(\"time this function was called.\\n\\n\")\n",
    "    \n",
    "    correct='0'\n",
    "    while correct=='0':\n",
    "        trainingpercent=float(input(\"Enter the proportion of the data you want to go into the training dataset as a number between 0 and 1,and then press enter\"))\n",
    "        testingpercent=float(input(\"Enter the proportion of the data you want to go into the testing dataset as a number between 0 and 1 and then press enter\"))\n",
    "        printabletraining=trainingpercent*100\n",
    "        printabletesting=testingpercent*100\n",
    "        printablevalidation=100-printabletraining-printabletesting\n",
    "        print(\"You have chosen the following approximate proportions\")\n",
    "        print(\"Training:   \"+ str(printabletraining)+ \"%\")\n",
    "        print(\"Testing:    \"+str(printabletesting)+ \"%\")\n",
    "        print(\"Validation: \"+ str(printablevalidation)+ \"%\")\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        correct=input(\"Is This Correct? \\n (0) no \\n (1) yes\")\n",
    "    newTraining=[]\n",
    "    newTesting=[]\n",
    "    newValidation=[]        \n",
    "    for x in data:\n",
    "        randomnumber=np.random.rand()            \n",
    "        if (randomnumber>1-trainingpercent):\n",
    "            newTraining.append(x)\n",
    "        elif (randomnumber>1-trainingpercent-testingpercent):\n",
    "           newTesting.append(x)\n",
    "        elif (randomnumber>0):                \n",
    "            newValidation.append(x)\n",
    "                \n",
    "                \n",
    "    convertedTraining=np.array(newTraining)\n",
    "    convertedTesting=np.array(newTesting)        \n",
    "    convertedValidation=np.array(newValidation)\n",
    "        \n",
    "    print(convertedTraining.shape)        \n",
    "    print(convertedTesting.shape)\n",
    "    print(convertedValidation.shape)\n",
    "        \n",
    "    chosen_name=input(\"Type the name you would like to save these datasets as: \")\n",
    "    trainingname=chosen_name+\"TRAINING.csv\"\n",
    "    testingname=chosen_name+\"TESTING.csv\"\n",
    "    validationname=chosen_name+\"VALIDATION.csv\"\n",
    "    np.savetxt(trainingname, convertedTraining, delimiter=',')\n",
    "    np.savetxt(testingname, convertedTesting, delimiter=',')\n",
    "    np.savetxt(validationname, convertedValidation, delimiter=',')\n",
    "    print(\"What data would you like to be your active data at the end of the execution of this function?\")\n",
    "    print(\"a: Previous Data\")\n",
    "    print(\"b: Partitioned Training Data\")\n",
    "    print(\"c: Partitioned Testing Data\")\n",
    "    print(\"d: Partitioned Validation Data\")\n",
    "    your_choice=input(\"Choice: \")\n",
    "    if (your_choice=='a'):\n",
    "        return data\n",
    "    elif (your_choice=='b'):\n",
    "        return convertedTraining\n",
    "    elif (your_choice=='c'):\n",
    "         return convertedTesting\n",
    "    elif (your_choice=='d'):\n",
    "        return convertedValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832fe49f-28b0-43f2-808e-6cb5abb281cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module lets the user define the architectrure of their neural net, including the activation function of each layer, numbe rof layers and number of neurons in each layer\n",
    "#it is worht indicating that since softmax isn't considered as an actiobvation function here because it isn't actually an activation function. Instead, the softmax is considered a part of various loss functions\n",
    "def define_architecture(inputdim):\n",
    "    numlayers=int(input(\"How Many layers would you  like the neural net to have, including the output layer, starting counting at the first hidden layer?\"))\n",
    "    numclasses=int(input(\"How many classes would you like to classify your data into?\"))\n",
    "    layerinputdim=inputdim\n",
    "    print(\"The currently loaded dataset is \")\n",
    "    print(inputdim)\n",
    "    print(\"dimensionsal.\")\n",
    "    print(\"For this reason the input dimension of layer 1 will be automatically set to equal\")\n",
    "    print(inputdim)\n",
    "    created_architecture=[]\n",
    "    for x in range(1,numlayers):\n",
    "        print(\"For layer \")\n",
    "        print(x)\n",
    "        print(\"Please select your desired activation function.\")\n",
    "        print(\"a.) relu (Rectified linear unit)\")\n",
    "        print(\"b.) sigmoid\")\n",
    "        print(\"c.) linear\")\n",
    "        activation_choice=input(\"Your Choice: \")\n",
    "        if(activation_choice == 'a'):\n",
    "            act=\"relu\"\n",
    "        elif(activation_choice =='b'):\n",
    "            act=\"sigmoid\"\n",
    "        elif(activation_choice=='c'):\n",
    "            act=\"linear\"\n",
    "        layeroutputdim=int(input(\"Choose an output dimensionality: \"))\n",
    "        current_layer={\"input_dim\": layerinputdim, \"output_dim\": layeroutputdim, \"activation\": act}\n",
    "        created_architecture.append(current_layer)\n",
    "        layerinputdim=layeroutputdim\n",
    "    print(\"For the final layer,\")\n",
    "    print(\"please select your desired activation function.\")\n",
    "    print(\"a.) relu (Rectified linear unit)\")\n",
    "    print(\"b.) sigmoid\")\n",
    "    print(\"c.) linear\")\n",
    "    activation_choice=input(\"Your Choice: \")\n",
    "    if(activation_choice == 'a'):\n",
    "        act=\"relu\"\n",
    "    elif(activation_choice =='b'):\n",
    "        act=\"sigmoid\"\n",
    "    elif(activation_choice=='c'):\n",
    "        act=\"linear\"\n",
    "    current_layer={\"input_dim\": layerinputdim, \"output_dim\": numclasses, \"activation\": act}\n",
    "    created_architecture.append(current_layer)\n",
    "    print(created_architecture)\n",
    "    return created_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6222f396-35de-441c-84e7-76eac94a71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function lets the user load an architecture from a previous session\n",
    "def load_architecture():\n",
    "    filename=input(\"Please give the filename of the architecture you would like to load\")\n",
    "    open_file=open(filename, \"rb\")\n",
    "    loaded_list=pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72fe1374-9e11-4f7a-86fd-ed693724775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function lets the user load weights from a previous session\n",
    "def load_weights():\n",
    "    filename=input(\"Please give the filename of the architecture you would like to load\")\n",
    "    open_file=open(filename, \"rb\")\n",
    "    loaded_list=pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62e8973f-5165-4653-94eb-0d988df50e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function lets the user save architectures for a different session\n",
    "def save_architecture(architecture):\n",
    "    file_name=input(\"What filename would you like to save the architecture to?\")\n",
    "    open_file=open(file_name,\"wb\")\n",
    "    pickle.dump(architecture,open_file)\n",
    "    open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1285691-398b-450f-babf-8ea42d287908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function lets the user save weights for a different session\n",
    "def save_weights(weights):\n",
    "    file_name=input(\"What filename would you like to save the weights to?\")\n",
    "    open_file=open(file_name,\"wb\")\n",
    "    pickle.dump(weights,open_file)\n",
    "    open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c59f2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the cell in which I will put the various activation functions and how they behave upon backwards propogation. \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def linear_backward(dA,x):\n",
    "    dx=np.array(dA,copy =True)\n",
    "    return dx;\n",
    "\n",
    "def relu_backward(dA,x):\n",
    "    dx=np.array(dA,copy =True)\n",
    "    dx[x<=0]=0;\n",
    "    return dx;\n",
    "\n",
    "def sigmoid_backward(dA,x):\n",
    "    sig=sigmoid(x)\n",
    "    return dA*sig*(1-sig)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef5aba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the cell in which I implement \"Initialize Weights and Biases\"\n",
    "def initialize_weights(architecture,seed=105):\n",
    "    np.random.seed(seed)\n",
    "    number_of_layers=len(architecture)\n",
    "    weight_values={}\n",
    "    print(\"\\nWould you like the initialized weights to have a Gaussian distribution or a uniform distribution?\\n\")\n",
    "    print(\"a: Gaussian\\n\")\n",
    "    print(\"b: Uniform\\n\")\n",
    "    choice=input(\"Distribution Choice: \")\n",
    "    print(\"\\nWhat would you  like to be the variance of the weights you initialize?\\n\")\n",
    "    variance=float(input(\"Chosen Variance: \"))\n",
    "    for identifier, layer in enumerate(architecture):\n",
    "        layer_identifier=identifier+1\n",
    "        layer_input_size=layer[\"input_dim\"]\n",
    "        layer_output_size=layer[\"output_dim\"]\n",
    "        if(choice=='a'):\n",
    "            weight_values['W'+str(layer_identifier)]=variance*np.random.randn(layer_output_size, layer_input_size)\n",
    "            weight_values['b'+str(layer_identifier)]=np.random.randn(layer_output_size, 1)*variance\n",
    "        elif(choice=='b'):\n",
    "            weight_values['W'+str(layer_identifier)]=np.random.rand(layer_output_size, layer_input_size)*variance\n",
    "            weight_values['b'+str(layer_identifier)]=np.random.rand(layer_output_size, 1)*variance\n",
    "    return weight_values\n",
    "            \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6334a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, I implement a single step of forward propogation\n",
    "def single_layer_forward_propogation(A_previous, W_current, b_current, activation):     \n",
    "    x_current=np.transpose(np.dot(W_current,np.transpose(A_previous))+b_current)\n",
    "    if activation == \"relu\":\n",
    "        activation_function=relu\n",
    "    elif activation == \"sigmoid\":\n",
    "        activation_function = sigmoid\n",
    "    elif activation == \"linear\":\n",
    "        activation_function=linear\n",
    "        \n",
    "    return activation_function(x_current), x_current\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1906c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, I implement full forward propogation through the network\n",
    "def full_forward_propogation(x, weight_values, architecture):\n",
    "    memory={}\n",
    "    A_current=x\n",
    "    for identifier, layer in enumerate(architecture):\n",
    "        layer_identifier=identifier+1\n",
    "        A_previous=A_current\n",
    "        current_activation_function=layer[\"activation\"]\n",
    "        W_current=weight_values[\"W\"+str(layer_identifier)]\n",
    "        b_current=weight_values[\"b\"+str(layer_identifier)]\n",
    "        A_current,  x_current=single_layer_forward_propogation(A_previous, W_current, b_current, layer[\"activation\"])\n",
    "        memory[\"A\"+str(identifier)]=A_previous\n",
    "        memory[\"X\"+str(layer_identifier)]=x_current\n",
    "    return A_current, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e44bfb-251a-4c06-beec-f13b54384ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#This function calculates the loss function for cross entropy with a softmax\n",
    "\n",
    "def get_loss(y_hat, y, learning_parameters):\n",
    "    if learning_parameters[\"loss_function\"]==\"cross_entropy\":\n",
    "        return cross_entropy_with_softmax(y_hat,y)\n",
    "    elif learning_parameters[\"loss_function\"]==\"hinge_loss\":\n",
    "        return hinge_loss(y_hat,y)\n",
    "    return 0\n",
    "\n",
    "def cross_entropy_with_softmax(y_hat, y):\n",
    "    y_hat_softmax=softmax(y_hat)\n",
    "    m=np.shape(y_hat_softmax)[1]\n",
    "    return (-1/m)*(np.tensordot(y,np.log(y_hat_softmax)))\n",
    "def cross_entropy_dA(y_hat, y):\n",
    "    y_hat_softmax=softmax(y_hat)\n",
    "    return y_hat_softmax-y\n",
    "        \n",
    "def hinge_loss(y_hat, y):\n",
    "    dood=np.transpose(np.array([np.transpose(np.array(y_hat)),np.transpose(np.array(y))]))\n",
    "    losses=[]\n",
    "    for point in dood:\n",
    "        other_point=np.transpose(point)\n",
    "        y_hat_sub=other_point[0]\n",
    "        y_sub=other_point[1]\n",
    "        losses.append(max(0,1-np.dot(y_hat_sub,y_sub)+max(y_hat_sub-y_hat_sub*y_sub)))\n",
    "    return sum(losses)/np.shape(np.array(y_hat))[0] \n",
    "\n",
    "\n",
    "def hinge_loss_dA(y_hat,y):\n",
    "    dood=np.transpose(np.array([np.transpose(np.array(y_hat)),np.transpose(np.array(y))]))\n",
    "    losses=[]\n",
    "    gradients=[]\n",
    "    for point in dood:\n",
    "        other_point=np.transpose(point)\n",
    "        y_hat_sub=other_point[0]\n",
    "        y_sub=other_point[1]\n",
    "        if(0==max(0,1-np.dot(y_hat_sub,y_sub)+max(y_hat_sub-y_hat_sub*y_sub))):\n",
    "            gradients.append(np.zeros(np.shape(y_sub)))\n",
    "        else:\n",
    "            gradients.append(-y_sub+np.where(y_hat_sub==max(y_hat_sub),1,0))\n",
    "    return np.array(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a71a525e-6b0e-4620-880b-5d7039236e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    soft_dood=[]\n",
    "    for dood in y:\n",
    "        dood_exp=np.exp(dood)\n",
    "        sum_exp=np.sum(dood_exp)\n",
    "        soft_dood.append(dood_exp/sum_exp)\n",
    "    return np.array(soft_dood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a1717e-7d51-428a-8605-e278c1732fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_backward_propogation(dA_current, w_current, b_current, x_current, A_previous, layer):\n",
    "    m=A_previous.shape[1]\n",
    "    if layer[\"activation\"] == \"relu\":\n",
    "        dx_current=relu_backward(dA_current,x_current)\n",
    "    elif layer[\"activation\"] == \"sigmoid\":\n",
    "        dx_current=sigmoid_backward(dA_current,x_current)\n",
    "    elif layer[\"activation\"] == \"linear\":\n",
    "        dx_current=linear_backward(dA_current,x_current)\n",
    "    dw_current=np.dot(np.transpose(A_previous),dx_current)/m\n",
    "    db_current=np.sum(dx_current,axis=0,keepdims=True)/m\n",
    "    dA_previous=np.dot(dx_current,w_current)\n",
    "    \n",
    "    return dA_previous, dw_current, db_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0faf82f-1718-458a-afa7-cfec0e1fca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def full_backward_propogation(y_hat, y, memory, weights, architecture, learning_parameters):\n",
    "    grads_values = {}\n",
    "    m = y.shape[1]\n",
    "    y = y.reshape(y_hat.shape)\n",
    "    if learning_parameters[\"loss_function\"] == \"cross_entropy\":\n",
    "        dA_previous =cross_entropy_dA(y_hat,y)\n",
    "    elif learning_parameters[\"loss_function\"] == \"hinge_loss\":\n",
    "        dA_previous=hing_loss_dA(y_hat,y)\n",
    "\n",
    "    gradient_current={}\n",
    "    for layer_id_previous, layer in reversed(list(enumerate(architecture))):\n",
    "        layer_id_current = layer_id_previous + 1\n",
    "        current_activation_function = layer[\"activation\"]\n",
    "        \n",
    "        dA_current = dA_previous\n",
    "        \n",
    "        A_previous = memory[\"A\" + str(layer_id_previous)]\n",
    "        x_current = memory[\"X\" + str(layer_id_current)]\n",
    "        w_current = weights[\"W\" + str(layer_id_current)]\n",
    "        b_current = weights[\"b\" + str(layer_id_current)]\n",
    "        \n",
    "        dA_previous, dw_current, db_current = single_layer_backward_propogation(\n",
    "            dA_current, w_current, b_current, x_current, A_previous, layer)\n",
    "        \n",
    "        gradient_current[\"dW\" + str(layer_id_current)] = dw_current\n",
    "        gradient_current[\"db\" + str(layer_id_current)] = db_current\n",
    "    \n",
    "    return gradient_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede59a81-a03f-4d6e-a1e7-b61b4aeb2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(weights, gradient, architecture, learning_parameters,batch_size):\n",
    "    for layer_id, layer in enumerate(architecture):\n",
    "        layerd=layer_id+1\n",
    "        weights[\"W\" + str(layerd)] -= (np.transpose(learning_parameters[\"learning_rate\"] * gradient[\"dW\" + str(layerd)])+learning_parameters[\"l2_regularizer\"]*weights[\"W\" + str(layerd)])  \n",
    "        weights[\"b\" + str(layerd)] -= (np.transpose(learning_parameters[\"learning_rate\"] * gradient[\"db\" + str(layerd)]))\n",
    "\n",
    "    return weights;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb8a968d-4ff1-471e-bcdd-04b89d36d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_to_model, architecture, weights, learning_parameters, cost_history, accuracy_history):\n",
    "    batch_size=int(input(\"How many data points would you like to make up a single batch.\\n Note that only full batches will be trained.\"))\n",
    "    epochnumber=int(input(\"How many epochs would you like to train for each batch?\"))\n",
    "    ### Splitting up data to model into batches\n",
    "    data_batches=[]\n",
    "    batch_being_built=[]\n",
    "    some_number=1\n",
    "    initial_y=[]\n",
    "    for data_points in data_to_model:\n",
    "        initial_y.append(np.array(data_points[0]))\n",
    "    num_classes=int(np.amax(initial_y)+1)\n",
    "    \n",
    "    for x in data_to_model:\n",
    "        batch_being_built.append(x)\n",
    "        if (batch_size==some_number):\n",
    "            batch_to_add=np.array(batch_being_built).astype(np.float64)\n",
    "            data_batches.append(batch_to_add)\n",
    "            batch_being_built=[]\n",
    "            some_number=0\n",
    "        some_number+=1\n",
    "        \n",
    "    loss_history=[]\n",
    "    accuracy_history=[]\n",
    "    n=0\n",
    "    for current_batch in data_batches:\n",
    "        print(\"starting a batch\")\n",
    "        input_doods, output_doods=split_data(current_batch, num_classes)\n",
    "        for i in range(0, epochnumber):\n",
    "            y_hat, cache = full_forward_propogation(input_doods, weights, architecture)\n",
    "            loss_value=get_loss(y_hat, output_doods, learning_parameters)\n",
    "            n+=1\n",
    "            if(n==100):\n",
    "                n=0\n",
    "                print(y_hat)\n",
    "                accuracy=get_accuracy_value(y_hat,output_doods,np.squeeze(np.shape(output_doods)[1]))\n",
    "                print(\"Accuracy\")\n",
    "                print(accuracy)\n",
    "                print(\"loss_value\")\n",
    "                print(loss_value)\n",
    "                quitnow=input(\"quit, y or n\")\n",
    "                accuracy_history.append(accuracy)\n",
    "                loss_history.append(loss_value)\n",
    "                if (quitnow=='y'):\n",
    "                    doodle=input(\"Really Quit (y), or just change training parameters (n)?\")\n",
    "                    if(doodle=='y'):\n",
    "                        return weights,loss_history, accuracy_history\n",
    "                    set_training_parameters()\n",
    "            gradients=full_backward_propogation(y_hat,output_doods,cache,weights,architecture, learning_parameters)\n",
    "            weights=update(weights,gradients,architecture,learning_parameters,batch_size)\n",
    "        accuracy=get_accuracy_value(y_hat,output_doods, np.squeeze(np.shape(output_doods)[1]))\n",
    "    return weights, loss_history, accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ceaac09-5328-4819-9a80-4fc99fc25b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_value(y_hat,output_doods,num_classes):\n",
    "    maxes=[]\n",
    "    for x in y_hat:\n",
    "        max_value=max(x)\n",
    "        maxes.append(x.tolist().index(max_value))\n",
    "    y_vector=np.array(maxes)\n",
    "    right_size_zeros=np.zeros((int(np.squeeze(np.shape(y_vector))), num_classes))\n",
    "    for stuff in range(0,np.squeeze(np.shape(y_vector))):\n",
    "        right_size_zeros[stuff][int(np.floor(.5+y_vector[stuff]))]=1\n",
    "    num_correct=np.tensordot(right_size_zeros,output_doods)\n",
    "    portion_correct=num_correct/np.shape(output_doods)[0]\n",
    "    print(\"number correct\")\n",
    "    print(num_correct)\n",
    "    print(\"Accuracy\")\n",
    "    print(portion_correct)\n",
    "    print(\"End_Accuracy\")\n",
    "    return portion_correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c4f40d1-86e1-438f-a165-4b8f6c27f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,num_classes):\n",
    "    initial_x=[]\n",
    "    initial_y=[]\n",
    "    m=np.squeeze(np.array(data[0]).shape)\n",
    "    for data_points in data:\n",
    "        initial_y.append(np.array(data_points[0]))\n",
    "        initial_x.append(np.array(data_points[1:]))\n",
    "    \n",
    "    y_vector=np.array(initial_y)\n",
    "    right_size_zeros=np.zeros((int(np.squeeze(np.shape(y_vector))), num_classes))\n",
    "    for stuff in range(0,np.squeeze(np.shape(y_vector))):\n",
    "        right_size_zeros[stuff][int(np.floor(.5+y_vector[stuff]))]=1\n",
    "    x_vector=np.array(initial_x)\n",
    "\n",
    "    return x_vector, right_size_zeros\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ae3ccf6-2601-4976-87aa-46877d29fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(data_to_test, architecture, weights, learning_parameters):\n",
    "    batch_size=int(input(\"How many data points would you like to test per batch\"))\n",
    "    data_batches=[]\n",
    "    batch_being_built=[]\n",
    "    some_number=1\n",
    "    initial_y=[]\n",
    "    for data_points in data_to_test:\n",
    "        initial_y.append(np.array(data_points[0]))\n",
    "    num_classes=int(np.amax(initial_y)+1)\n",
    "    for x in data_to_test:\n",
    "        batch_being_built.append(x)\n",
    "        if (batch_size==some_number):\n",
    "            batch_to_add=np.array(batch_being_built).astype(np.float64)\n",
    "            data_batches.append(batch_to_add)\n",
    "            batch_being_built=[]\n",
    "            some_number=0\n",
    "        some_number+=1\n",
    "    accuracy_history=[]\n",
    "    loss_history=[]\n",
    "    n=0\n",
    "    for current_batch in data_batches:\n",
    "        input_doods, output_doods=split_data(current_batch, num_classes)\n",
    "        y_hat,cache=full_forward_propogation(input_doods, weights, architecture)\n",
    "        loss_value=get_loss(y_hat,output_doods,learning_parameters)\n",
    "        accuracy=get_accuracy_value(y_hat, output_doods, np.squeeze(np.shape(output_doods)[1]))\n",
    "        print(\"Accuracy\")\n",
    "        print(accuracy)\n",
    "        print(\"loss_value\")\n",
    "        print(loss_value)\n",
    "        accuracy_history.append(accuracy)\n",
    "        loss_history.append(loss_value)\n",
    "    print(\"Loss History\")\n",
    "    print(loss_history)\n",
    "    print(\"Accuracy_history\")\n",
    "    print(accuracy_history)\n",
    "    total=sum(accuracy_history)\n",
    "    length=len(accuracy_history)\n",
    "    print(\"Overall Accuracy\")\n",
    "    print(total/length)\n",
    "    \n",
    "    return loss_history, accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a56304-3c65-4f35-9e1e-f15715d5eb91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome To Multi-Layer Perceptron-inator 3000\n",
      "\n",
      "\n",
      "\n",
      "Select an option by typing the Indicated letter and pressing  \"Enter\" \n",
      "\n",
      "\n",
      "a:  Load csv of data to model\n",
      "b: Partition  loaded data into Training, Testing, and Validation\n",
      "c: Manually Define MLP Architecture which is compatible with loaded data\n",
      "d: Load MLP Architecture From Previous Session which is compatible with loaded data\n",
      "e: Initialize weights and biases for use with training\n",
      "f: Load weights and biases from previous session\n",
      "g: Save Current Architecture For Future Session\n",
      "h: Save Current Weights For Future Session\n",
      "i: Choose Training Parameters\n",
      "j: Save Training Parameters\n",
      "k: Load Training Parameters\n",
      "l: Quit Program Without Saving\n",
      "m: Train Model\n",
      "n: Test Models\n",
      "o: Print Accuracy History\n",
      "p: Print Loss History\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Choice:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please provide the file name of the csv that you would like to read as data.\n",
      "\n",
      "Each line of this File should represent a single data point, and the first entry of each line should indicate to what class a given data point belongs\n",
      "\n",
      "Your selection should include the .csv as its extension\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Filename:  mnist_train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Select an option by typing the Indicated letter and pressing  \"Enter\" \n",
      "\n",
      "\n",
      "a:  Load csv of data to model\n",
      "b: Partition  loaded data into Training, Testing, and Validation\n",
      "c: Manually Define MLP Architecture which is compatible with loaded data\n",
      "d: Load MLP Architecture From Previous Session which is compatible with loaded data\n",
      "e: Initialize weights and biases for use with training\n",
      "f: Load weights and biases from previous session\n",
      "g: Save Current Architecture For Future Session\n",
      "h: Save Current Weights For Future Session\n",
      "i: Choose Training Parameters\n",
      "j: Save Training Parameters\n",
      "k: Load Training Parameters\n",
      "l: Quit Program Without Saving\n",
      "m: Train Model\n",
      "n: Test Models\n",
      "o: Print Accuracy History\n",
      "p: Print Loss History\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Choice:  d\n",
      "Please give the filename of the architecture you would like to load short_n_fat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Select an option by typing the Indicated letter and pressing  \"Enter\" \n",
      "\n",
      "\n",
      "a:  Load csv of data to model\n",
      "b: Partition  loaded data into Training, Testing, and Validation\n",
      "c: Manually Define MLP Architecture which is compatible with loaded data\n",
      "d: Load MLP Architecture From Previous Session which is compatible with loaded data\n",
      "e: Initialize weights and biases for use with training\n",
      "f: Load weights and biases from previous session\n",
      "g: Save Current Architecture For Future Session\n",
      "h: Save Current Weights For Future Session\n",
      "i: Choose Training Parameters\n",
      "j: Save Training Parameters\n",
      "k: Load Training Parameters\n",
      "l: Quit Program Without Saving\n",
      "m: Train Model\n",
      "n: Test Models\n",
      "o: Print Accuracy History\n",
      "p: Print Loss History\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Choice:  f\n",
      "Please give the filename of the architecture you would like to load well_trained_short_n_fat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Select an option by typing the Indicated letter and pressing  \"Enter\" \n",
      "\n",
      "\n",
      "a:  Load csv of data to model\n",
      "b: Partition  loaded data into Training, Testing, and Validation\n",
      "c: Manually Define MLP Architecture which is compatible with loaded data\n",
      "d: Load MLP Architecture From Previous Session which is compatible with loaded data\n",
      "e: Initialize weights and biases for use with training\n",
      "f: Load weights and biases from previous session\n",
      "g: Save Current Architecture For Future Session\n",
      "h: Save Current Weights For Future Session\n",
      "i: Choose Training Parameters\n",
      "j: Save Training Parameters\n",
      "k: Load Training Parameters\n",
      "l: Quit Program Without Saving\n",
      "m: Train Model\n",
      "n: Test Models\n",
      "o: Print Accuracy History\n",
      "p: Print Loss History\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Choice:  e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Would you like the initialized weights to have a Gaussian distribution or a uniform distribution?\n",
      "\n",
      "a: Gaussian\n",
      "\n",
      "b: Uniform\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Distribution Choice:  b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What would you  like to be the variance of the weights you initialize?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chosen Variance:  .01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Select an option by typing the Indicated letter and pressing  \"Enter\" \n",
      "\n",
      "\n",
      "a:  Load csv of data to model\n",
      "b: Partition  loaded data into Training, Testing, and Validation\n",
      "c: Manually Define MLP Architecture which is compatible with loaded data\n",
      "d: Load MLP Architecture From Previous Session which is compatible with loaded data\n",
      "e: Initialize weights and biases for use with training\n",
      "f: Load weights and biases from previous session\n",
      "g: Save Current Architecture For Future Session\n",
      "h: Save Current Weights For Future Session\n",
      "i: Choose Training Parameters\n",
      "j: Save Training Parameters\n",
      "k: Load Training Parameters\n",
      "l: Quit Program Without Saving\n",
      "m: Train Model\n",
      "n: Test Models\n",
      "o: Print Accuracy History\n",
      "p: Print Loss History\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Choice:  i\n",
      "What learning rate would you like to use? .0001\n",
      "What hyperparameter would you like to use for the\n",
      " L2 regularizer? (If no regularizer is to be used, hit '0' .00001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The options for loss functions are as follows:\n",
      "a.) cross entropy with softmax\n",
      "b.) hinge loss\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your choice:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Select an option by typing the Indicated letter and pressing  \"Enter\" \n",
      "\n",
      "\n",
      "a:  Load csv of data to model\n",
      "b: Partition  loaded data into Training, Testing, and Validation\n",
      "c: Manually Define MLP Architecture which is compatible with loaded data\n",
      "d: Load MLP Architecture From Previous Session which is compatible with loaded data\n",
      "e: Initialize weights and biases for use with training\n",
      "f: Load weights and biases from previous session\n",
      "g: Save Current Architecture For Future Session\n",
      "h: Save Current Weights For Future Session\n",
      "i: Choose Training Parameters\n",
      "j: Save Training Parameters\n",
      "k: Load Training Parameters\n",
      "l: Quit Program Without Saving\n",
      "m: Train Model\n",
      "n: Test Models\n",
      "o: Print Accuracy History\n",
      "p: Print Loss History\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Choice:  m\n",
      "How many data points would you like to make up a single batch.\n",
      " Note that only full batches will be trained. 128\n",
      "How many epochs would you like to train for each batch? 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting a batch\n",
      "[[0.81123697 0.63574019 0.64769747 ... 0.61029589 0.57023527 0.62787732]\n",
      " [0.83917325 0.65261071 0.66582726 ... 0.62438171 0.57947379 0.64369051]\n",
      " [0.74333819 0.60063417 0.60953068 ... 0.58138382 0.55141454 0.59467673]\n",
      " ...\n",
      " [0.80406354 0.63161087 0.64325941 ... 0.60701987 0.56799221 0.62401471]\n",
      " [0.82176517 0.64154052 0.65428819 ... 0.61555647 0.57378506 0.63374017]\n",
      " [0.7773931  0.61766084 0.6279703  ... 0.59526885 0.56038231 0.61060999]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "29.160376263226198\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85090574 0.63867438 0.63530173 ... 0.56055393 0.49139106 0.5857953 ]\n",
      " [0.87805071 0.65585733 0.65213755 ... 0.56847935 0.49025249 0.59660866]\n",
      " [0.78072723 0.60294253 0.60012086 ... 0.54465646 0.49380278 0.56336649]\n",
      " ...\n",
      " [0.84373055 0.63445484 0.63118048 ... 0.55877998 0.49165458 0.58315655]\n",
      " [0.86124035 0.64456209 0.64140576 ... 0.56358991 0.49123545 0.58985018]\n",
      " [0.81651782 0.62022521 0.61705153 ... 0.55230679 0.49270278 0.57409558]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "29.06424104167676\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85545073 0.61817315 0.61258915 ... 0.50540263 0.42780928 0.53271144]\n",
      " [0.88243395 0.63303544 0.62687353 ... 0.5060339  0.41831853 0.53666174]\n",
      " [0.78518977 0.58761961 0.58304894 ... 0.50440063 0.44729182 0.52444652]\n",
      " ...\n",
      " [0.84827501 0.61451879 0.60909301 ... 0.50538795 0.4301036  0.53173208]\n",
      " [0.86574164 0.62319006 0.6177643  ... 0.50583229 0.42467194 0.53431805]\n",
      " [0.82102115 0.60235949 0.59721358 ... 0.50502231 0.43813831 0.5284593 ]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "29.02074672617931\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85129405 0.57834138 0.58826781 ... 0.45963727 0.3809976  0.48476839]\n",
      " [0.87852444 0.5883435  0.59964659 ... 0.45414536 0.36578242 0.48229326]\n",
      " [0.78104217 0.55815831 0.56495304 ... 0.47105043 0.4125612  0.4895238 ]\n",
      " ...\n",
      " [0.84405682 0.57587183 0.5854791  ... 0.46110213 0.38471821 0.48534034]\n",
      " [0.86167153 0.5815775  0.59239525 ... 0.45787855 0.37579642 0.48409017]\n",
      " [0.81667275 0.56792326 0.57610564 ... 0.465857   0.39768998 0.48742888]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.991160516323692\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84539586 0.52991977 0.56415785 ... 0.42417481 0.34349058 0.4462872 ]\n",
      " [0.87293342 0.53357807 0.57251688 ... 0.41405289 0.32414495 0.43868941]\n",
      " [0.77523348 0.52278005 0.54715981 ... 0.44506555 0.38419506 0.46144046]\n",
      " ...\n",
      " [0.83809083 0.52898645 0.56210191 ... 0.42677074 0.34827498 0.44810633]\n",
      " [0.8558774  0.53086079 0.56720168 ... 0.42075283 0.33677883 0.44378328]\n",
      " [0.8105727  0.52639701 0.55529207 ... 0.43545333 0.36497626 0.45449956]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.967528429485725\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8391999  0.48602284 0.54029319 ... 0.3961613  0.310842   0.41577309]\n",
      " [0.86702843 0.48373846 0.54555779 ... 0.38252606 0.28834837 0.40423017]\n",
      " [0.76921008 0.49088999 0.5296506  ... 0.42436034 0.35895251 0.43902617]\n",
      " ...\n",
      " [0.83183344 0.4865278  0.53898769 ... 0.39962902 0.31647055 0.41856627]\n",
      " [0.84977562 0.48482471 0.54222966 ... 0.39146982 0.30295981 0.41185767]\n",
      " [0.80420319 0.4889134  0.53477927 ... 0.41135692 0.33618618 0.42833087]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.948843049223424\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83285669 0.45291178 0.51695226 ... 0.373693   0.28153816 0.39146105]\n",
      " [0.86094973 0.44614574 0.51911833 ... 0.35736532 0.25665938 0.37689287]\n",
      " [0.76312161 0.46682051 0.51258794 ... 0.40759213 0.33573067 0.42101723]\n",
      " ...\n",
      " [0.82543754 0.45450805 0.51639935 ... 0.37784076 0.28783984 0.39501376]\n",
      " [0.84350995 0.45009927 0.5177824  ... 0.36802578 0.27275351 0.3864613 ]\n",
      " [0.79772481 0.46066526 0.51478184 ... 0.39195954 0.3100193  0.40741808]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.934879468945397\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82664762 0.42978266 0.49481256 ... 0.35580351 0.25526159 0.37225016]\n",
      " [0.85496981 0.41992356 0.49400053 ... 0.33742504 0.22866469 0.35538321]\n",
      " [0.75723181 0.44995653 0.49642779 ... 0.39411383 0.31434283 0.40666307]\n",
      " ...\n",
      " [0.81918576 0.43213875 0.49498529 ... 0.36047888 0.2620828  0.37639028]\n",
      " [0.83735759 0.42585262 0.49458255 ... 0.34939513 0.2458145  0.36642919]\n",
      " [0.79142018 0.44093008 0.49585348 ... 0.37646375 0.28622775 0.39084447]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.924894884664333\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82097933 0.4137989  0.47456646 ... 0.34184364 0.231939   0.35734473]\n",
      " [0.84949219 0.40182113 0.47101935 ... 0.32192348 0.20420114 0.33875321]\n",
      " [0.75190793 0.43827297 0.48164437 ... 0.38350684 0.29481747 0.39543725]\n",
      " ...\n",
      " [0.8134836  0.41667974 0.4754087  ... 0.34692293 0.23914188 0.36193325]\n",
      " [0.83172563 0.40910118 0.47336698 ... 0.33488372 0.22204135 0.35091403]\n",
      " [0.78568478 0.42729898 0.4785624  ... 0.36434322 0.2647973  0.37795721]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.917908850024766\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81614254 0.40259801 0.45663882 ... 0.33117485 0.21139829 0.34599141]\n",
      " [0.84481394 0.38913417 0.45067552 ... 0.31010579 0.182993   0.32611626]\n",
      " [0.74739758 0.43007879 0.46853012 ... 0.37534443 0.27711945 0.3868303 ]\n",
      " ...\n",
      " [0.80861868 0.40584911 0.4580759  ... 0.3365604  0.21886524 0.35091919]\n",
      " [0.82690953 0.3973606  0.45458773 ... 0.32381163 0.20122644 0.33911548]\n",
      " [0.78079148 0.4177658  0.4632555  ... 0.35507216 0.24563535 0.36813266]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.912963202272\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81221115 0.39458465 0.4411104  ... 0.32311915 0.19331316 0.33742909]\n",
      " [0.84101968 0.38004384 0.43306773 ... 0.30119094 0.16461113 0.31659474]\n",
      " [0.74374636 0.42422405 0.45713947 ... 0.36914979 0.26108203 0.38030706]\n",
      " ...\n",
      " [0.80466166 0.39810486 0.44306272 ... 0.32873739 0.20094862 0.34261416]\n",
      " [0.82298896 0.38895515 0.43833162 ... 0.31546307 0.18300658 0.33023009]\n",
      " [0.77679912 0.41097157 0.44999427 ... 0.34807892 0.22850576 0.36072945]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.909303710008658\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80909097 0.38870633 0.42779742 ... 0.31702837 0.17727108 0.33095155]\n",
      " [0.8380248  0.37335557 0.41798691 ... 0.29444615 0.14855688 0.30938742]\n",
      " [0.74085124 0.41994418 0.44734182 ... 0.36445059 0.24644388 0.37535575]\n",
      " ...\n",
      " [0.80151624 0.3924288  0.43019082 ... 0.32282627 0.18499907 0.33633488]\n",
      " [0.81987429 0.38278086 0.42440532 ... 0.30915829 0.16693742 0.32351656]\n",
      " [0.77360572 0.40601646 0.4386202  ... 0.34280756 0.21307903 0.35514378]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.906422005814274\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80661864 0.3842604  0.41637681 ... 0.31235201 0.16285165 0.32596901]\n",
      " [0.83567218 0.36827507 0.40506299 ... 0.28925671 0.13434718 0.30383268]\n",
      " [0.73855289 0.41672505 0.43890752 ... 0.36083636 0.23290725 0.37154008]\n",
      " ...\n",
      " [0.79901814 0.38814067 0.41914795 ... 0.31829255 0.17061118 0.33150939]\n",
      " [0.81740494 0.37810173 0.41246856 ... 0.30432258 0.15257478 0.31835833]\n",
      " [0.77104619 0.40229774 0.42885853 ... 0.3387805  0.19900018 0.35086633]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.90400324379533\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80463114 0.38077528 0.4064848  ... 0.30866241 0.14967467 0.32202797]\n",
      " [0.83380222 0.36427099 0.39387974 ... 0.28514905 0.12156145 0.29942573]\n",
      " [0.73669752 0.41421959 0.43157658 ... 0.35798337 0.2201796  0.36851986]\n",
      " ...\n",
      " [0.79700419 0.38478363 0.40958269 ... 0.3147203  0.15741475 0.32769719]\n",
      " [0.8154193  0.37442437 0.4021385  ... 0.30051091 0.13952267 0.31428271]\n",
      " [0.76895888 0.39940985 0.42040025 ... 0.33562396 0.18593411 0.34750281]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.901857353801883\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80299412 0.3779347  0.39777273 ... 0.30564636 0.13741936 0.31879857]\n",
      " [0.83228223 0.36098781 0.38403935 ... 0.28177836 0.10985667 0.29580137]\n",
      " [0.73516044 0.41219397 0.42509818 ... 0.35565204 0.20799451 0.36604523]\n",
      " ...\n",
      " [0.79534023 0.3820511  0.40115809 ... 0.31180449 0.14509465 0.32457747]\n",
      " [0.81378369 0.37141817 0.39304876 ... 0.29739807 0.12745108 0.31094655]\n",
      " [0.76721188 0.39708032 0.41294873 ... 0.33306276 0.17358648 0.34476503]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.89986708250407\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80163328 0.37551715 0.38994474 ... 0.30310221 0.12583818 0.31606507]\n",
      " [0.83103869 0.35817707 0.37520516 ... 0.27892332 0.09897578 0.29272148]\n",
      " [0.73387279 0.41048377 0.4192583  ... 0.35368742 0.19613055 0.36395198]\n",
      " ...\n",
      " [0.79395209 0.37972829 0.39358811 ... 0.30934856 0.13340565 0.32194026]\n",
      " [0.81242411 0.36885177 0.38488877 ... 0.29477493 0.11610802 0.3081257 ]\n",
      " [0.76573227 0.39511799 0.40625185 ... 0.33091935 0.16172117 0.34246412]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.897956705126163\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80045794 0.37339719 0.38276698 ... 0.30088853 0.11475881 0.31367983]\n",
      " [0.82998098 0.3556982  0.36711179 ... 0.27642916 0.08874429 0.29002352]\n",
      " [0.73275219 0.40899575 0.41388696 ... 0.3519803  0.1844201  0.36212728]\n",
      " ...\n",
      " [0.79274945 0.37769353 0.3866465  ... 0.30721451 0.1221755  0.31964171]\n",
      " [0.81124972 0.36659418 0.37741332 ... 0.29249491 0.10531965 0.30566685]\n",
      " [0.76443229 0.39341451 0.40010994 ... 0.32906899 0.15016653 0.34047062]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.896073196486512\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79937536 0.37147778 0.37595616 ... 0.2988364  0.10399906 0.3114779 ]\n",
      " [0.82901617 0.35344251 0.35944004 ... 0.27411224 0.07898934 0.28752701]\n",
      " [0.73171478 0.40765774 0.40877512 ... 0.35039846 0.17266251 0.36044351]\n",
      " ...\n",
      " [0.79164025 0.3758526  0.38005892 ... 0.30523744 0.11121918 0.31752103]\n",
      " [0.8101676  0.36454408 0.37032641 ... 0.29038361 0.09490636 0.30339933]\n",
      " [0.76322214 0.3918862  0.39427959 ... 0.32736147 0.13872767 0.3386389 ]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.894169420759898\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79837218 0.36967619 0.36930716 ... 0.29688699 0.09347008 0.30939348]\n",
      " [0.82813088 0.35131753 0.35195992 ... 0.27190868 0.06963159 0.28515998]\n",
      " [0.73074819 0.40640788 0.4037702  ... 0.34889606 0.16073568 0.35884992]\n",
      " ...\n",
      " [0.79061135 0.37412513 0.37362648 ... 0.30335983 0.10044417 0.31551399]\n",
      " [0.80916449 0.36261513 0.36341421 ... 0.28838041 0.08478248 0.30125512]\n",
      " [0.76208878 0.39046153 0.38858396 ... 0.32574463 0.12729727 0.336911  ]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.892206074204097\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79741807 0.36794528 0.36263413 ... 0.29499088 0.08314041 0.30737448]\n",
      " [0.82729458 0.34927061 0.34446442 ... 0.26976503 0.06064754 0.28286564]\n",
      " [0.72982507 0.40521096 0.39873234 ... 0.34743436 0.14856564 0.35730614]\n",
      " ...\n",
      " [0.78963275 0.37246528 0.36716872 ... 0.3015333  0.0898152  0.31356967]\n",
      " [0.80820994 0.36075814 0.35648348 ... 0.28643439 0.07491952 0.29918042]\n",
      " [0.76100297 0.38909979 0.38286194 ... 0.32417445 0.11582236 0.3352409 ]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.890145566285874\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79649439 0.36625022 0.35576334 ... 0.29311571 0.07303999 0.30538658]\n",
      " [0.82648843 0.34726288 0.33676161 ... 0.26764642 0.05206833 0.28060672]\n",
      " [0.72892857 0.4040409  0.39352894 ... 0.34598793 0.13613968 0.35578555]\n",
      " ...\n",
      " [0.78868609 0.3708391  0.36051664 ... 0.29972607 0.0793596  0.31165443]\n",
      " [0.80728518 0.35893675 0.34935421 ... 0.28451233 0.06534847 0.29713988]\n",
      " [0.75994676 0.38777087 0.37696194 ... 0.32262203 0.10431395 0.33359824]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.887951178008304\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79557895 0.36457048 0.3485178  ... 0.29123607 0.06325642 0.30340369]\n",
      " [0.82568999 0.34527146 0.32865774 ... 0.26552563 0.04397079 0.278355  ]\n",
      " [0.72803879 0.40288235 0.3880228  ... 0.3445367  0.12351465 0.35426782]\n",
      " ...\n",
      " [0.78774955 0.36922652 0.35349771 ... 0.29791315 0.06916508 0.30974265]\n",
      " [0.80636787 0.3571295  0.34184365 ... 0.28258818 0.05615413 0.29510668]\n",
      " [0.75889886 0.38645708 0.37072825 ... 0.3210646  0.09285017 0.33195988]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.885588610300523\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79465861 0.3628912  0.34071233 ... 0.28934118 0.05392973 0.30141393]\n",
      " [0.82488597 0.34327977 0.31995237 ... 0.26339128 0.03646681 0.2760977 ]\n",
      " [0.72714398 0.40172416 0.38206769 ... 0.34307213 0.11082811 0.35274366]\n",
      " ...\n",
      " [0.78681029 0.36761295 0.34593097 ... 0.29608386 0.05937634 0.30782255]\n",
      " [0.80544478 0.35532079 0.33376138 ... 0.28065102 0.04746786 0.29306868]\n",
      " [0.7578467  0.3851456  0.36399644 ... 0.31949242 0.08157991 0.33031525]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.883029955465783\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79372092 0.36120466 0.33213785 ... 0.28742908 0.04523102 0.29941413]\n",
      " [0.8240638  0.34127918 0.31042192 ... 0.26124144 0.02967986 0.27383149]\n",
      " [0.7262331  0.40056053 0.3754953  ... 0.34159268 0.09829232 0.35121066]\n",
      " ...\n",
      " [0.78585613 0.36599076 0.33761159 ... 0.2942361  0.05017492 0.30589087]\n",
      " [0.80450339 0.35350248 0.32489335 ... 0.27869899 0.03944527 0.29102273]\n",
      " [0.75677835 0.3838298  0.35657887 ... 0.31790366 0.07070868 0.32866158]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.88025920580554\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79274749 0.35950931 0.32253197 ... 0.28549578 0.03732879 0.29739968]\n",
      " [0.82320501 0.33926785 0.29978896 ... 0.25907196 0.02371474 0.27155142]\n",
      " [0.72528986 0.39939034 0.36809046 ... 0.34009508 0.08616798 0.34966517]\n",
      " ...\n",
      " [0.78486897 0.36435829 0.32828187 ... 0.29236587 0.0417453  0.303943  ]\n",
      " [0.8035252  0.35167277 0.31497185 ... 0.27672811 0.03223329 0.28896419]\n",
      " [0.75567614 0.38250849 0.34823759 ... 0.31629465 0.06046668 0.32699478]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.877276680922638\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79172639 0.35779667 0.31154062 ... 0.28353924 0.03035512 0.29536703]\n",
      " [0.82229774 0.3372361  0.28768355 ... 0.25688069 0.01863209 0.26925358]\n",
      " [0.72430384 0.39820717 0.35955745 ... 0.33857759 0.07472639 0.3481043 ]\n",
      " ...\n",
      " [0.78383708 0.36270721 0.31759322 ... 0.29047111 0.03423939 0.30197536]\n",
      " [0.80249827 0.34982261 0.30363702 ... 0.27473638 0.0259391  0.28688946]\n",
      " [0.75452853 0.38117451 0.33864808 ... 0.31466351 0.0510701  0.32531177]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.874099626701494\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79064631 0.35604502 0.29864265 ... 0.28154719 0.02437698 0.29330188]\n",
      " [0.82133081 0.33515953 0.27356763 ... 0.25465441 0.01443229 0.26692237]\n",
      " [0.72326532 0.3969945  0.34945283 ... 0.33703022 0.0642006  0.34651664]\n",
      " ...\n",
      " [0.78274928 0.36101641 0.30503121 ... 0.28853981 0.0277445  0.29997398]\n",
      " [0.8014113  0.34792927 0.29036098 ... 0.2727113  0.02060561 0.28478388]\n",
      " [0.75332461 0.37980922 0.32732724 ... 0.31299926 0.0426791  0.32359992]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.87075429635063\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78947976 0.35421567 0.28301532 ... 0.27947569 0.01938439 0.29115879]\n",
      " [0.8202767  0.33299474 0.25660417 ... 0.25234592 0.01105564 0.26450857]\n",
      " [0.72215051 0.39572281 0.33706076 ... 0.33541736 0.05474269 0.34486585]\n",
      " ...\n",
      " [0.78157833 0.35924831 0.28978113 ... 0.28652902 0.02226777 0.29789449]\n",
      " [0.80023676 0.34595237 0.274314   ... 0.27060784 0.01620417 0.28260076]\n",
      " [0.75203822 0.37837929 0.31350185 ... 0.31126237 0.0353686  0.3218188 ]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.867255710687136\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78819252 0.35222825 0.26333496 ... 0.277242   0.01530039 0.28885276]\n",
      " [0.81910084 0.3306522  0.23547814 ... 0.24986674 0.00839869 0.26192059]\n",
      " [0.72093003 0.39433077 0.32118825 ... 0.33367188 0.04640489 0.34308377]\n",
      " ...\n",
      " [0.78029032 0.35732497 0.27052526 ... 0.28435782 0.01774347 0.29565386]\n",
      " [0.79894026 0.34380854 0.25417051 ... 0.26834136 0.01264697 0.2802529 ]\n",
      " [0.75063711 0.37681513 0.29590037 ... 0.30937826 0.02912383 0.31989244]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.863567533264302\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78671534 0.34995813 0.23753841 ... 0.27469296 0.0120009  0.28622915]\n",
      " [0.81773276 0.32799351 0.20822947 ... 0.24705369 0.00633519 0.25899254]\n",
      " [0.71954425 0.39272302 0.29985341 ... 0.33166901 0.03913777 0.34104598]\n",
      " ...\n",
      " [0.77881663 0.35512547 0.24518959 ... 0.28187629 0.01405175 0.293101  ]\n",
      " [0.79745198 0.34136882 0.22789136 ... 0.26575526 0.00980783 0.2775818 ]\n",
      " [0.74905636 0.37500855 0.27246021 ... 0.30720836 0.02385144 0.31768211]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.859516170631107\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78496725 0.34721661 0.20298261 ... 0.27160708 0.00933952 0.28306483]\n",
      " [0.81608928 0.32481005 0.17262231 ... 0.24367218 0.00473644 0.25548643]\n",
      " [0.71792417 0.39075466 0.2701149  ... 0.32922719 0.03280685 0.33857179]\n",
      " ...\n",
      " [0.77707713 0.35246673 0.21105316 ... 0.27886741 0.01104383 0.29001765]\n",
      " [0.79569009 0.3384385  0.19294858 ... 0.26262357 0.00754558 0.27435927]\n",
      " [0.747221   0.37279509 0.24027845 ... 0.30455137 0.01940303 0.31498664]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.85460205993478\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78286912 0.34384638 0.15851983 ... 0.26775403 0.00717263 0.2791317 ]\n",
      " [0.81408802 0.32092958 0.12858273 ... 0.23948114 0.00348796 0.2511619 ]\n",
      " [0.71600329 0.38830346 0.22926005 ... 0.32615459 0.02722721 0.33547361]\n",
      " ...\n",
      " [0.77499357 0.34919601 0.16671695 ... 0.2751051  0.00856932 0.28618035]\n",
      " [0.79357423 0.33485616 0.14852471 ... 0.2587123  0.00572641 0.27035299]\n",
      " [0.74505878 0.37003655 0.19718522 ... 0.30119559 0.01560802 0.31159814]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.84773972083771\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78045818 0.34000156 0.10962926 ... 0.26321799 0.00539982 0.27452151]\n",
      " [0.81176482 0.31652609 0.08300917 ... 0.2345775  0.00251066 0.24612434]\n",
      " [0.71381656 0.385484   0.17938712 ... 0.32251192 0.02226618 0.33181798]\n",
      " ...\n",
      " [0.77260285 0.3454627  0.11724927 ... 0.270671   0.00652272 0.28167804]\n",
      " [0.79114127 0.33078251 0.10058109 ... 0.25411019 0.00425716 0.26565962]\n",
      " [0.74260672 0.36686466 0.14673181 ... 0.29721122 0.01234605 0.30759357]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.837705099265612\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77800823 0.33635968 0.06818399 ... 0.25875179 0.00399319 0.26999432]\n",
      " [0.80939969 0.31235005 0.04741391 ... 0.22976516 0.00177059 0.24119016]\n",
      " [0.71160172 0.38281347 0.13041533 ... 0.31890913 0.01796897 0.32821374]\n",
      " ...\n",
      " [0.77017584 0.34192443 0.07446671 ... 0.2663026  0.00488008 0.27725394]\n",
      " [0.78866769 0.32691702 0.06095771 ... 0.24958827 0.00310704 0.26105921]\n",
      " [0.74012065 0.36386861 0.10006866 ... 0.2932771  0.00961984 0.30365365]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.825124171846745\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77588702 0.33361669 0.04062359 ... 0.25526018 0.00294241 0.26645733]\n",
      " [0.80737303 0.30916602 0.02584803 ... 0.22599735 0.00124353 0.23732116]\n",
      " [0.70967366 0.38082826 0.09169206 ... 0.31609332 0.01445744 0.32540079]\n",
      " ...\n",
      " [0.76807591 0.33925718 0.04535268 ... 0.26288823 0.00363842 0.27379702]\n",
      " [0.78652645 0.32397463 0.03535962 ... 0.2460687  0.00225967 0.25747852]\n",
      " [0.73793996 0.361658   0.0657231  ... 0.29021948 0.00747295 0.30060091]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.81256447460355\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77428628 0.33188088 0.02454295 ... 0.25300854 0.00219303 0.264174  ]\n",
      " [0.80588646 0.30708739 0.01436572 ... 0.22354455 0.0008848  0.23478735]\n",
      " [0.70819357 0.37961564 0.06479087 ... 0.31429323 0.01172374 0.32360305]\n",
      " ...\n",
      " [0.76649187 0.3375666  0.0279723  ... 0.26068993 0.0027426  0.27156682]\n",
      " [0.78491305 0.322063   0.02084057 ... 0.24381858 0.00166348 0.25518326]\n",
      " [0.73623839 0.36033163 0.04354398 ... 0.28828822 0.00586135 0.29868156]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.801780314365285\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n y\n",
      "Really Quit (y), or just change training parameters (n)? n\n",
      "What learning rate would you like to use? .001\n",
      "What hyperparameter would you like to use for the\n",
      " L2 regularizer? (If no regularizer is to be used, hit '0' .0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The options for loss functions are as follows:\n",
      "a.) cross entropy with softmax\n",
      "b.) hinge loss\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your choice:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.73148812e-01 3.30884019e-01 1.54382432e-02 ... 2.51712134e-01\n",
      "  1.66639312e-03 2.62858142e-01]\n",
      " [8.04884704e-01 3.05814223e-01 8.38234807e-03 ... 2.22099485e-01\n",
      "  6.43595534e-04 2.33277529e-01]\n",
      " [7.07109713e-01 3.78971553e-01 4.69174115e-02 ... 3.13280832e-01\n",
      "  9.63754095e-03 3.22593853e-01]\n",
      " ...\n",
      " [7.65366582e-01 3.36592514e-01 1.79249480e-02 ... 2.59429351e-01\n",
      "  2.10615371e-03 2.70284005e-01]\n",
      " [7.83770974e-01 3.20902640e-01 1.28262917e-02 ... 2.42544810e-01\n",
      "  1.24978940e-03 2.53878077e-01]\n",
      " [7.34959124e-01 3.59658161e-01 2.97678771e-02 ... 2.87229342e-01\n",
      "  4.67294719e-03 2.97642338e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.793018935703824\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.72325555e-01 3.30336541e-01 1.01704024e-02 ... 2.50989972e-01\n",
      "  1.29364682e-03 2.62127916e-01]\n",
      " [8.04216484e-01 3.05025116e-01 5.16460183e-03 ... 2.21257833e-01\n",
      "  4.79716054e-04 2.32383382e-01]\n",
      " [7.06293347e-01 3.78673697e-01 3.50094541e-02 ... 3.12743743e-01\n",
      "  8.04435774e-03 3.22063998e-01]\n",
      " ...\n",
      " [7.64552418e-01 3.36053860e-01 1.20044702e-02 ... 2.58732851e-01\n",
      "  1.65112271e-03 2.69574836e-01]\n",
      " [7.82950311e-01 3.20193248e-01 8.29073707e-03 ... 2.41857827e-01\n",
      "  9.60373053e-04 2.53171526e-01]\n",
      " [7.33961521e-01 3.59386147e-01 2.11194504e-02 ... 2.86697377e-01\n",
      "  3.79362416e-03 2.97139964e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.78589967905972\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.71700235e-01 3.30033266e-01 6.99821581e-03 ... 2.50576709e-01\n",
      "  1.02531779e-03 2.61716106e-01]\n",
      " [8.03763413e-01 3.04492487e-01 3.34753920e-03 ... 2.20739339e-01\n",
      "  3.66109279e-04 2.31820301e-01]\n",
      " [7.05644673e-01 3.78564007e-01 2.68976458e-02 ... 3.12462967e-01\n",
      "  6.81486245e-03 3.21795748e-01]\n",
      " ...\n",
      " [7.63934290e-01 3.35751490e-01 8.38181821e-03 ... 2.58340018e-01\n",
      "  1.32052479e-03 2.69177586e-01]\n",
      " [7.82333838e-01 3.19722144e-01 5.61131308e-03 ... 2.41486828e-01\n",
      "  7.54228354e-04 2.52790151e-01]\n",
      " [7.33136296e-01 3.59337260e-01 1.55256779e-02 ... 2.86450582e-01\n",
      "  3.13432466e-03 2.96933280e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.77997367826115\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.71182978e-01 3.29870217e-01 5.00379635e-03 ... 2.50315488e-01\n",
      "  8.28217487e-04 2.61465628e-01]\n",
      " [8.03434149e-01 3.04100303e-01 2.26824288e-03 ... 2.20378773e-01\n",
      "  2.85507216e-04 2.31421151e-01]\n",
      " [7.05086771e-01 3.78562221e-01 2.12146679e-02 ... 3.12308581e-01\n",
      "  5.85243117e-03 3.21660702e-01]\n",
      " ...\n",
      " [7.63423302e-01 3.35584548e-01 6.07191805e-03 ... 2.58096885e-01\n",
      "  1.07562776e-03 2.68938384e-01]\n",
      " [7.81830915e-01 3.19381042e-01 3.95456730e-03 ... 2.41271970e-01\n",
      "  6.04257250e-04 2.52573397e-01]\n",
      " [7.32398781e-01 3.59421610e-01 1.17803156e-02 ... 2.86345626e-01\n",
      "  2.63162524e-03 2.96880376e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.774880341292544\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.70725355e-01 3.29788084e-01 3.69799192e-03 ... 2.50129508e-01\n",
      "  6.80489712e-04 2.61298915e-01]\n",
      " [8.03180073e-01 3.03781596e-01 1.59656046e-03 ... 2.20095379e-01\n",
      "  2.27000161e-04 2.31103182e-01]\n",
      " [7.04578335e-01 3.78622365e-01 1.71199756e-02 ... 3.12216883e-01\n",
      "  5.08779024e-03 3.21595396e-01]\n",
      " ...\n",
      " [7.62971496e-01 3.35495584e-01 4.54056035e-03 ... 2.57928089e-01\n",
      "  8.90651397e-04 2.68781292e-01]\n",
      " [7.81392822e-01 3.19107601e-01 2.88562985e-03 ... 2.41135173e-01\n",
      "  4.92834639e-04 2.52442109e-01]\n",
      " [7.31702891e-01 3.59588361e-01 9.18714127e-03 ... 2.86312226e-01\n",
      "  2.24171260e-03 2.96911414e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.77035572064444\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.70302415e-01 3.29751567e-01 2.81145052e-03 ... 2.49983727e-01\n",
      "  5.67644948e-04 2.61180093e-01]\n",
      " [8.02976950e-01 3.03495557e-01 1.16091655e-03 ... 2.19852387e-01\n",
      "  1.83614098e-04 2.30827753e-01]\n",
      " [7.04098143e-01 3.78716916e-01 1.40919482e-02 ... 3.12158779e-01\n",
      "  4.47155495e-03 3.21570477e-01]\n",
      " ...\n",
      " [7.62554072e-01 3.35450508e-01 3.48919693e-03 ... 2.57799268e-01\n",
      "  7.48345970e-04 2.68671238e-01]\n",
      " [7.80994594e-01 3.18864088e-01 2.16927261e-03 ... 2.41040974e-01\n",
      "  4.08401391e-04 2.52359768e-01]\n",
      " [7.31024180e-01 3.59807823e-01 7.33611831e-03 ... 2.86318258e-01\n",
      "  1.93431920e-03 2.96994446e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.766209838457215\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.69885058e-01 3.29755279e-01 2.19001838e-03 ... 2.49855004e-01\n",
      "  4.79918889e-04 2.61087103e-01]\n",
      " [8.02796620e-01 3.03233893e-01 8.67966752e-04 ... 2.19625562e-01\n",
      "  1.50801745e-04 2.30570749e-01]\n",
      " [7.03621408e-01 3.78841411e-01 1.17996820e-02 ... 3.12115028e-01\n",
      "  3.96821251e-03 3.21567883e-01]\n",
      " ...\n",
      " [7.62142144e-01 3.35444326e-01 2.74475425e-03 ... 2.57687747e-01\n",
      "  6.36990081e-04 2.68586710e-01]\n",
      " [7.80607145e-01 3.18643350e-01 1.67293234e-03 ... 2.40966064e-01\n",
      "  3.43242882e-04 2.52303987e-01]\n",
      " [7.30333970e-01 3.60076763e-01 5.97851258e-03 ... 2.86342469e-01\n",
      "  1.68827880e-03 2.97110149e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.762303241138273\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.69466411e-01 3.29784150e-01 1.74209543e-03 ... 2.49737839e-01\n",
      "  4.10635516e-04 2.61014096e-01]\n",
      " [8.02634101e-01 3.02977259e-01 6.64682483e-04 ... 2.19409196e-01\n",
      "  1.25543994e-04 2.30325047e-01]\n",
      " [7.03142379e-01 3.78983811e-01 1.00280394e-02 ... 3.12081072e-01\n",
      "  3.55206907e-03 3.21582866e-01]\n",
      " ...\n",
      " [7.61728678e-01 3.35462724e-01 2.20321848e-03 ... 2.57588170e-01\n",
      "  5.48510604e-04 2.68522103e-01]\n",
      " [7.80223882e-01 3.18428121e-01 1.31889738e-03 ... 2.40905134e-01\n",
      "  2.92129496e-04 2.52268948e-01]\n",
      " [7.29624048e-01 3.60383682e-01 4.95877134e-03 ... 2.86379815e-01\n",
      "  1.48864345e-03 2.97254105e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.758530415988787\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.69036006e-01 3.29833736e-01 1.41125119e-03 ... 2.49627853e-01\n",
      "  3.55128643e-04 2.60957271e-01]\n",
      " [8.02481160e-01 3.02717442e-01 5.19694051e-04 ... 2.19198752e-01\n",
      "  1.05787946e-04 2.30085511e-01]\n",
      " [7.02652233e-01 3.79140219e-01 8.63340062e-03 ... 3.12053279e-01\n",
      "  3.20418876e-03 3.21612335e-01]\n",
      " ...\n",
      " [7.61303040e-01 3.35501805e-01 1.79985705e-03 ... 2.57496279e-01\n",
      "  4.77226085e-04 2.68473846e-01]\n",
      " [7.79834637e-01 3.18211845e-01 1.05986820e-03 ... 2.40854029e-01\n",
      "  2.51434869e-04 2.52250930e-01]\n",
      " [7.28882428e-01 3.60726750e-01 4.17657262e-03 ... 2.86426291e-01\n",
      "  1.32464246e-03 2.97423901e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.754807488358455\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.68579059e-01 3.29908774e-01 1.16158032e-03 ... 2.49519659e-01\n",
      "  3.10077984e-04 2.60912826e-01]\n",
      " [8.02325659e-01 3.02455647e-01 4.13764973e-04 ... 2.18988624e-01\n",
      "  9.01096375e-05 2.29846793e-01]\n",
      " [7.02138476e-01 3.79313767e-01 7.51753093e-03 ... 3.12027163e-01\n",
      "  2.91042411e-03 3.21653176e-01]\n",
      " ...\n",
      " [7.60850254e-01 3.35566715e-01 1.49310160e-03 ... 2.57406821e-01\n",
      "  4.19068224e-04 2.68438410e-01]\n",
      " [7.79424918e-01 3.17997160e-01 8.66074779e-04 ... 2.40807574e-01\n",
      "  2.18597329e-04 2.52246209e-01]\n",
      " [7.28092611e-01 3.61112628e-01 3.56538411e-03 ... 2.86476971e-01\n",
      "  1.18839353e-03 2.97617300e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.751064646588304\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.68090546e-01 3.30004750e-01 9.69572550e-04 ... 2.49414024e-01\n",
      "  2.73087150e-04 2.60882185e-01]\n",
      " [8.02166066e-01 3.02182157e-01 3.34717585e-04 ... 2.18779656e-01\n",
      "  7.75048666e-05 2.29608799e-01]\n",
      " [7.01597082e-01 3.79500228e-01 6.61175984e-03 ... 3.12003404e-01\n",
      "  2.66011000e-03 3.21706571e-01]\n",
      " ...\n",
      " [7.60364843e-01 3.35653776e-01 1.25550509e-03 ... 2.57320593e-01\n",
      "  3.71084033e-04 2.68417441e-01]\n",
      " [7.78990202e-01 3.17776883e-01 7.18215257e-04 ... 2.40766926e-01\n",
      "  1.91780226e-04 2.52256443e-01]\n",
      " [7.27246792e-01 3.61540250e-01 3.07997160e-03 ... 2.86532639e-01\n",
      "  1.07406330e-03 2.97837075e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.747239780202\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.67555368e-01 3.30130321e-01 8.19410993e-04 ... 2.49306844e-01\n",
      "  2.42389859e-04 2.60863529e-01]\n",
      " [8.01991266e-01 3.01900738e-01 2.74611941e-04 ... 2.18567561e-01\n",
      "  6.72500029e-05 2.29367700e-01]\n",
      " [7.01015591e-01 3.79705316e-01 5.86701362e-03 ... 3.11978658e-01\n",
      "  2.44504127e-03 3.21771029e-01]\n",
      " ...\n",
      " [7.59831270e-01 3.35772291e-01 1.06845876e-03 ... 2.57233610e-01\n",
      "  3.31084940e-04 2.68409483e-01]\n",
      " [7.78515941e-01 3.17556897e-01 6.03420962e-04 ... 2.40728344e-01\n",
      "  1.69638381e-04 2.52280026e-01]\n",
      " [7.26327190e-01 3.62020613e-01 2.68882466e-03 ... 2.86589657e-01\n",
      "  9.77244350e-04 2.98083316e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.743274312189506\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.66965067e-01 3.30286111e-01 7.00211462e-04 ... 2.49198332e-01\n",
      "  2.16671633e-04 2.60858643e-01]\n",
      " [8.01797878e-01 3.01605136e-01 2.28140100e-04 ... 2.18352595e-01\n",
      "  5.88173079e-05 2.29123103e-01]\n",
      " [7.00387264e-01 3.79928402e-01 5.24760735e-03 ... 3.11953135e-01\n",
      "  2.25887684e-03 3.21847940e-01]\n",
      " ...\n",
      " [7.59240310e-01 3.35924065e-01 9.19065940e-04 ... 2.57146122e-01\n",
      "  2.97434204e-04 2.68416695e-01]\n",
      " [7.77994268e-01 3.17334594e-01 5.12909405e-04 ... 2.40692474e-01\n",
      "  1.51176372e-04 2.52319022e-01]\n",
      " [7.25321427e-01 3.62558470e-01 2.36955645e-03 ... 2.86648323e-01\n",
      "  8.94584748e-04 2.98359671e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.739110150685505\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.66312387e-01 3.30470183e-01 6.04321790e-04 ... 2.49090467e-01\n",
      "  1.94939502e-04 2.60870900e-01]\n",
      " [8.01584840e-01 3.01284858e-01 1.91669764e-04 ... 2.18136846e-01\n",
      "  5.18156687e-05 2.28875812e-01]\n",
      " [6.99706718e-01 3.80166430e-01 4.72713585e-03 ... 3.11928590e-01\n",
      "  2.09665368e-03 3.21939987e-01]\n",
      " ...\n",
      " [7.58583669e-01 3.36108753e-01 7.98199589e-04 ... 2.57060117e-01\n",
      "  2.68889754e-04 2.68442910e-01]\n",
      " [7.77418734e-01 3.17104167e-01 4.40553185e-04 ... 2.40661878e-01\n",
      "  1.35646317e-04 2.52377205e-01]\n",
      " [7.24217532e-01 3.63156985e-01 2.10595386e-03 ... 2.86710653e-01\n",
      "  8.23500481e-04 2.98671647e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.734686672030236\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.65584041e-01 3.30687521e-01 5.26251936e-04 ... 2.48981609e-01\n",
      "  1.76429530e-04 2.60901336e-01]\n",
      " [8.01346356e-01 3.00935113e-01 1.62660689e-04 ... 2.17918620e-01\n",
      "  4.59498961e-05 2.28623615e-01]\n",
      " [6.98963642e-01 3.80421357e-01 4.28571704e-03 ... 3.11903749e-01\n",
      "  1.95441232e-03 3.22047824e-01]\n",
      " ...\n",
      " [7.57846761e-01 3.36333196e-01 6.99270721e-04 ... 2.56974031e-01\n",
      "  2.44491652e-04 2.68489827e-01]\n",
      " [7.76776876e-01 3.16866398e-01 3.81987531e-04 ... 2.40635467e-01\n",
      "  1.22475832e-04 2.52455998e-01]\n",
      " [7.22996745e-01 3.63826534e-01 1.88605375e-03 ... 2.86775326e-01\n",
      "  7.61961591e-04 2.99023032e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.729937525760533\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quit, y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.64758259e-01 3.30951671e-01 4.61998762e-04 ... 2.48868660e-01\n",
      "  1.60549814e-04 2.60950661e-01]\n",
      " [8.01069755e-01 3.00558139e-01 1.39304256e-04 ... 2.17694712e-01\n",
      "  4.09951983e-05 2.28363258e-01]\n",
      " [6.98140847e-01 3.80701313e-01 3.90819035e-03 ... 3.11876096e-01\n",
      "  1.82898347e-03 3.22171699e-01]\n",
      " ...\n",
      " [7.57006170e-01 3.36613178e-01 6.17447202e-04 ... 2.56884855e-01\n",
      "  2.23493135e-04 2.68559014e-01]\n",
      " [7.76047730e-01 3.16630293e-01 3.34050832e-04 ... 2.40610694e-01\n",
      "  1.11223544e-04 2.52556523e-01]\n",
      " [7.21630996e-01 3.64586392e-01 1.70090346e-03 ... 2.86839671e-01\n",
      "  7.08366107e-04 2.99417828e-01]]\n",
      "number correct\n",
      "18.0\n",
      "Accuracy\n",
      "0.140625\n",
      "End_Accuracy\n",
      "Accuracy\n",
      "0.140625\n",
      "loss_value\n",
      "28.724787901436272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## #This is the \"main\" function of the multi-layer Perceptron-inator 3000, and just initializes the loop in which the user  chooses what tasks to performs\n",
    "#\n",
    "\n",
    "#Imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Welcome To Multi-Layer Perceptron-inator 3000\\n\")\n",
    "AskUserWhatToDo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f45787-a148-4d01-8d04-e3f1a739d488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cbe5d-19da-44cc-9957-fd24c777433e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadfa6b-9312-45dd-8894-1cdfa113f1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
